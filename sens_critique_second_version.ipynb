{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install unidecode scikit-learn BeautifulSoup4 pandas requests lxml selenium regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Get the film data from the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reasons why I chose the following features:\n",
    "1. It's easy to manage numerical and categorical values for future predictions.\n",
    "2. After going through several online projects regarding movie predictions, I found the most commonly used features from IMDb datasets to be `languages`, `budgets`, `genres`, `runtime`, `vote_average`, `vote_count`.\n",
    "3. After checking the SensCritique website, I found features that might be useful for prediction. \n",
    "   1. The chosen features:\n",
    "      1. Numerical: `ranking`, `year`, `duration`, `stars`, `favorites`, `saves`, `number of critiques`.\n",
    "      2. Categorical: `director`, `genres`, `group`, `country of origin (pays d'origine)`.\n",
    "      3. Other: `original_title` could be used to create a linked table with information from IMDb datasets.\n",
    "   2. The features that I did not choose:\n",
    "      1. `Synopsis`: Requires further NLP (Natural Language Processing) analysis, which could make it challenging to process and find a link to the ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dict_main_page = {\n",
    "    'rating': {'name': 'div', 'attrs': {\"data-testid\": \"Rating\"}},\n",
    "    'director': {'name': 'a', 'attrs': {\"data-testid\": \"link\"}},\n",
    "    'duration': {'name': 'span', 'attrs': {\"data-testid\": \"duration\"}},\n",
    "    'genres': {'name': 'span', 'attrs': {\"data-testid\": \"genres\"}},\n",
    "    'ranking': {'name': 'span', 'attrs':{'data-testid': 'product-title-wrapper'}}\n",
    "}\n",
    "\n",
    "search_dict_film_page = {\n",
    "    'film_year': {'name': 'p', 'attrs': {\"class\": \"Text__SCTitle-sc-1aoldkr-1 CoverProductInfos__StyledText-sc-1un0kh1-13 eGhlHy jugtWW\"}},\n",
    "    'original_title':{'name': 'p', 'attrs': {\"class\": \"Text__SCTitle-sc-1aoldkr-1 CoverProductInfos__StyledText-sc-1un0kh1-13 eGhlHy kuMSsq\"}}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestSensCritique:\n",
    "    def __init__(self):\n",
    "        self._base_urls = 'https://www.senscritique.com/'\n",
    "    \n",
    "    def create_soup(self, content, is_url=True):\n",
    "        if is_url:\n",
    "            page_content = requests.get(content).content\n",
    "        else:\n",
    "            page_content = content\n",
    "        \n",
    "        return BeautifulSoup(page_content, \"html.parser\")\n",
    "\n",
    "    def find_text(self, element, search_criteria):\n",
    "        found_element = element.find(**search_criteria)\n",
    "        return found_element.text if found_element else None\n",
    "\n",
    "    def get_full_page(self, link):\n",
    "        full_url = self._base_urls + link\n",
    "        driver = webdriver.Chrome()\n",
    "\n",
    "        try:\n",
    "            driver.get(full_url)\n",
    "\n",
    "            for _ in range(8):\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "            \n",
    "            page_source = driver.page_source\n",
    "\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "        return self.create_soup(page_source, is_url=False)\n",
    "        \n",
    "    def get_film_page_info(self, film_link, dict_name):\n",
    "        film_url = self._base_urls + film_link\n",
    "        film_page_soup = self.create_soup(film_url)\n",
    "\n",
    "        film_page_dict = {key: self.find_text(film_page_soup, criteria) for key, criteria in dict_name.items()}\n",
    "\n",
    "        stats_elements = film_page_soup.select('p.Text__SCText-sc-1aoldkr-0.Stats__Text-sc-1u6v943-2.gATBvI')\n",
    "        if len(stats_elements) == 3:\n",
    "            film_page_dict['stars'] = stats_elements[0].text\n",
    "            film_page_dict['saves'] = stats_elements[1].text\n",
    "            film_page_dict['favorites'] = stats_elements[2].text\n",
    "        \n",
    "        critique_number_text = film_page_soup.select('.NavigationTab__WrapperTextStyled-sc-18dtd9d-7')[2].text\n",
    "        film_page_dict['critique_number'] = int(critique_number_text.split('(')[-1].split(')')[0])\n",
    "\n",
    "        # certain movies do not have film_group and origin_country\n",
    "        group_label = film_page_soup.find('span', string='Groupe : ')\n",
    "        if group_label:\n",
    "            film_page_dict['film_group'] = group_label.find_next('a', {'class': 'Text__SCText-sc-1aoldkr-0 Link__PrimaryLink-sc-1v081j9-0 gATBvI bGxijB'}).text\n",
    "\n",
    "        country_label = film_page_soup.find('h3', string=re.compile('Pays d\\'origine :'))\n",
    "        if country_label:\n",
    "            film_page_dict['origin_country'] = country_label.find_next_sibling('span').get_text()\n",
    "        \n",
    "        return film_page_dict\n",
    "    \n",
    "    def get_main_page(self, link, main_dict, film_info_dict):\n",
    "        film_soup = self.get_full_page(link)\n",
    "\n",
    "        films = film_soup.find_all('div', class_=\"ProductListItem__Wrapper-sc-1jkxxpj-1 kusRkg\")\n",
    "\n",
    "        all_films_dict = {}\n",
    "\n",
    "        for film in films:\n",
    "            title = self.find_text(film, {'name': 'a', 'attrs': {\"data-testid\": \"product-title\"}})\n",
    "\n",
    "            new_film_dict = {key: self.find_text(film, criteria) for key, criteria in main_dict.items()}\n",
    "\n",
    "            film_link = film.find('a', {\"data-testid\": \"product-title\"})['href']\n",
    "            new_film_dict.update(self.get_film_page_info(film_link, film_info_dict))\n",
    "            \n",
    "            all_films_dict[title] = new_film_dict\n",
    "        \n",
    "        return all_films_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_request = RequestSensCritique()\n",
    "\n",
    "top_111_link = 'films/tops/top111'\n",
    "films_info_dict = create_request.get_main_page(top_111_link, search_dict_main_page,search_dict_film_page )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to the json file\n",
    "with open('film_info.json', 'w') as json_file:\n",
    "    json.dump(films_info_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read and Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Getting to know the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('film_info.json', orient='index')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5,random_state=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed Problems from the sample:\n",
    "1. The first column should be named as `title`, and we should delete the year from the title.\n",
    "2. `duration` should be converted to `int` for future analysis. For example, `1 h 36 min.` should be converted to `96`.\n",
    "3. `genres` should use the `exploded` function to save them to separate rows.\n",
    "4. `stars`, `saves`, and `favorites` should be converted to numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['origin_country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to delete the commas in the column of `origin_country`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['director'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['film_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summaries from the info:\n",
    "1. There are two films that don't have `genres`, check the website to validate the correctness. -> They don't have genres on the website as well.\n",
    "2. `film_group` has lots of empty data, so I won't use it to do the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_genres = df[df['genres'].isna()]\n",
    "\n",
    "empty_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Clean the Data\n",
    "Based on what I've observed from the sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the first column to title\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df.rename(columns={'index': 'title'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the title without the year\n",
    "def clean_title(title):\n",
    "    return re.sub(r' \\(\\d{4}\\)', '', title)\n",
    "  \n",
    "    \n",
    "df['clean_title'] = df['title'].apply(clean_title)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration to numerique values\n",
    "def convert_to_minutes(duration_str):\n",
    "    parts = duration_str.split()\n",
    "    hours = int(parts[0])\n",
    "    minutes = int(parts[-2])\n",
    "    total_minutes = hours * 60 + minutes\n",
    "\n",
    "    return total_minutes\n",
    "\n",
    "df['duration_minutes'] = df['duration'].apply(convert_to_minutes)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ranking number from ranking column\n",
    "df['ranking_number'] = df['ranking'].str.split('.').str.get(0)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the commas in the column of `origin_country`.\n",
    "df['origin_country_clean'] = df['origin_country'].str.replace(',', ' ')\n",
    "\n",
    "# clean the extra space here\n",
    "df['origin_country_clean'] = df['origin_country_clean'].str.strip()\n",
    "\n",
    "df['origin_country_clean'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert stars, saves favorites to numbers\n",
    "def deal_with_k(number_str):\n",
    "    if 'K' in number_str:\n",
    "        parts = number_str.split('K')[0]\n",
    "        return int(float(parts) * 1000)\n",
    "    else:\n",
    "        return int(number_str)\n",
    "\n",
    "df['stars_number'] = df['stars'].apply(deal_with_k)\n",
    "df['saves_number'] = df['saves'].apply(deal_with_k)\n",
    "df['favorites_number'] = df['favorites'].apply(deal_with_k)\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process genres\n",
    "df['genres_split'] = df['genres'].str.split(', ')\n",
    "\n",
    "# Exploding the DataFrame\n",
    "exploded_df = df.explode('genres_split')\n",
    "\n",
    "# Performing one-hot encoding\n",
    "one_hot_encoded_df = pd.get_dummies(exploded_df, columns=['genres_split'], prefix='', prefix_sep='')\n",
    "\n",
    "# Grouping by title and aggregating the one-hot encoded genres\n",
    "final_df = one_hot_encoded_df.groupby('title').sum().reset_index()\n",
    "\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Movie Popularity Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare the dataframes for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I selected these features is to analyze the ratings and rankings on this website more effectively. These may be influenced by preferences towards specific directors or countries. \n",
    "\n",
    "Additionally, by examining these features, we might uncover relationships between the ratings and various factors such as the number of stars, saves, favorites, and critiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_temp_df = df[['clean_title','director','origin_country_clean', 'genres_split', 'duration_minutes','stars_number','saves_number','favorites_number','critique_number','film_year']]\n",
    "\n",
    "labels_df = df[['ranking_number', 'rating']]\n",
    "\n",
    "ranking_df = labels_df['ranking_number']\n",
    "rating_df = labels_df['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Deal with numerique datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the dataset and drop values that would be outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_temp_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Deal with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we have empty values in the categorical data\n",
    "features_temp_df.isnull().any()\n",
    "\n",
    "# create a copy of it\n",
    "features_temp_df = features_temp_df.copy()\n",
    "\n",
    "features_temp_df[features_temp_df.isnull().values==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna instead of dropna, as we need to have the same amout of data in features_df and labels_df\n",
    "features_temp_df['origin_country_clean'].fillna(\"empty\", inplace = True)\n",
    "features_temp_df['genres_split'].fillna(\"empty\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_temp_df[features_temp_df.isnull().values==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Creating an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fitting and transforming the director column\n",
    "features_temp_df['director_encoded'] = label_encoder.fit_transform(features_temp_df['director'])\n",
    "\n",
    "features_temp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting one-hot encoded columns for origin_country_clean\n",
    "country_dummies = pd.get_dummies(features_temp_df['origin_country_clean'], prefix='country')\n",
    "\n",
    "# Concatenating the one-hot encoded columns to the original dataframe\n",
    "features_temp_df = pd.concat([features_temp_df, country_dummies], axis=1)\n",
    "\n",
    "features_temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploding the DataFrame\n",
    "exploded_df = features_temp_df.explode('genres_split')\n",
    "\n",
    "# Performing one-hot encoding\n",
    "one_hot_encoded_df = pd.get_dummies(exploded_df, columns=['genres_split'], prefix='', prefix_sep='')\n",
    "\n",
    "# Grouping by title and aggregating the one-hot encoded genres\n",
    "features_df = one_hot_encoded_df.groupby('clean_title').sum().reset_index()\n",
    "\n",
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['film_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8.7\n",
       "1    8.6\n",
       "2    8.5\n",
       "3    8.5\n",
       "4    8.5\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important step to ensure the labels align with the features.\n",
    "rating_df = rating_df.loc[features_df.index]\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "Name: ranking_number, dtype: object"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_df = ranking_df.loc[features_df.index]\n",
    "ranking_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume that they have the same length\n",
    "assert len(features_df) == len(rating_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features_df, ranking_df, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['film_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12, 12\n",
    "\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "fig.suptitle('Numerical Feature Histograms', y=1.05, fontsize=16)\n",
    "\n",
    "axs[0, 0].hist(x_train['film_year'].values, bins=30, color='salmon')\n",
    "axs[0, 0].set_title('film_year')\n",
    "\n",
    "axs[0, 1].hist(x_train['duration_minutes'].values, bins=30, color='salmon')\n",
    "axs[0, 1].set_title('duration_minutes')\n",
    "\n",
    "axs[1, 0].hist(x_train['stars_number'].values, bins=30, color='salmon')\n",
    "axs[1, 0].set_title('stars_number')\n",
    "\n",
    "axs[1, 1].hist(x_train['saves_number'].values, bins=30, color='salmon')\n",
    "axs[1, 1].set_title('saves_number')\n",
    "\n",
    "axs[2, 0].hist(x_train['favorites_number'].values, bins=30, color='salmon')\n",
    "axs[2, 0].set_title('favorites_number')\n",
    "\n",
    "axs[2, 1].hist(x_train['critique_number'].values, bins=30, color='salmon')\n",
    "axs[2, 1].set_title('critique_number')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except for `film_year`, other plots seem to be skewed distribution. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
