{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.11/site-packages (1.3.7)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: BeautifulSoup4 in /usr/local/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (2.28.2)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/site-packages (4.9.2)\n",
      "Requirement already satisfied: selenium in /usr/local/lib/python3.11/site-packages (4.14.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/site-packages (2023.3.23)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/site-packages (from BeautifulSoup4) (2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in /usr/local/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unidecode scikit-learn BeautifulSoup4 pandas requests lxml selenium regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import requests\n",
    "import locale\n",
    "import pickle\n",
    "import re \n",
    "import lxml\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_dict_main_page = {\n",
    "    'rating': {'name': 'div', 'attrs': {\"data-testid\": \"Rating\"}},\n",
    "    'director': {'name': 'a', 'attrs': {\"data-testid\": \"link\"}},\n",
    "    'duration': {'name': 'span', 'attrs': {\"data-testid\": \"duration\"}},\n",
    "    'genres': {'name': 'span', 'attrs': {\"data-testid\": \"genres\"}},\n",
    "    'ranking': {'name': 'span', 'attrs':{'data-testid': 'product-title-wrapper'}}\n",
    "}\n",
    "\n",
    "search_dict_film_page = {\n",
    "    'film_year': {'name': 'p', 'attrs': {\"class\": \"Text__SCTitle-sc-1aoldkr-1 CoverProductInfos__StyledText-sc-1un0kh1-13 eGhlHy jugtWW\"}},\n",
    "    'original_title':{'name': 'p', 'attrs': {\"class\": \"Text__SCTitle-sc-1aoldkr-1 CoverProductInfos__StyledText-sc-1un0kh1-13 eGhlHy kuMSsq\"}}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestSensCritique:\n",
    "    def __init__(self):\n",
    "        self._base_urls = 'https://www.senscritique.com/'\n",
    "    \n",
    "    def create_soup(self, content, is_url=True):\n",
    "        if is_url:\n",
    "            page_content = requests.get(content).content\n",
    "        else:\n",
    "            page_content = content\n",
    "        \n",
    "        return BeautifulSoup(page_content, \"html.parser\")\n",
    "\n",
    "    def find_text(self, element, search_criteria):\n",
    "        found_element = element.find(**search_criteria)\n",
    "        return found_element.text if found_element else None\n",
    "\n",
    "    def get_full_page(self, link):\n",
    "        full_url = self._base_urls + link\n",
    "        driver = webdriver.Chrome()\n",
    "\n",
    "        try:\n",
    "            driver.get(full_url)\n",
    "\n",
    "            for _ in range(8):\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "            \n",
    "            page_source = driver.page_source\n",
    "\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "        return self.create_soup(page_source, is_url=False)\n",
    "        \n",
    "    def get_film_page_info(self, film_link, dict_name):\n",
    "        film_url = self._base_urls + film_link\n",
    "        film_page_soup = self.create_soup(film_url)\n",
    "\n",
    "        film_page_dict = {key: self.find_text(film_page_soup, criteria) for key, criteria in dict_name.items()}\n",
    "\n",
    "        stats_elements = film_page_soup.select('p.Text__SCText-sc-1aoldkr-0.Stats__Text-sc-1u6v943-2.gATBvI')\n",
    "        if len(stats_elements) == 3:\n",
    "            film_page_dict['stars'] = stats_elements[0].text\n",
    "            film_page_dict['saves'] = stats_elements[1].text\n",
    "            film_page_dict['favorites'] = stats_elements[2].text\n",
    "        \n",
    "        critique_number_text = film_page_soup.select('.NavigationTab__WrapperTextStyled-sc-18dtd9d-7')[2].text\n",
    "        film_page_dict['critique_number'] = int(critique_number_text.split('(')[-1].split(')')[0])\n",
    "\n",
    "        return film_page_dict\n",
    "    \n",
    "    def get_main_page(self, link, main_dict, film_info_dict):\n",
    "        film_soup = self.get_full_page(link)\n",
    "\n",
    "        films = film_soup.find_all('div', class_=\"ProductListItem__Wrapper-sc-1jkxxpj-1 kusRkg\")\n",
    "\n",
    "        all_films_dict = {}\n",
    "        count = 0\n",
    "\n",
    "        for film in films:\n",
    "            if count <= 2:\n",
    "                title = self.find_text(film, {'name': 'a', 'attrs': {\"data-testid\": \"product-title\"}})\n",
    "\n",
    "                new_film_dict = {key: self.find_text(film, criteria) for key, criteria in main_dict.items()}\n",
    "\n",
    "                film_link = film.find('a', {\"data-testid\": \"product-title\"})['href']\n",
    "                new_film_dict.update(self.get_film_page_info(film_link, film_info_dict))\n",
    "                \n",
    "                all_films_dict[title] = new_film_dict\n",
    "                count += 1\n",
    "        \n",
    "        return all_films_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.google.com')\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Douze Hommes en colÃ¨re (1957)': {'rating': '8.7',\n",
       "  'director': 'Sidney Lumet',\n",
       "  'duration': '1 h 36 min. ',\n",
       "  'genres': 'Policier, Drame',\n",
       "  'ranking': '1. Douze Hommes en colÃ¨re (1957)',\n",
       "  'film_year': '1957',\n",
       "  'original_title': None,\n",
       "  'stars': '51.7K',\n",
       "  'saves': '16.3K',\n",
       "  'favorites': '6.8K',\n",
       "  'critique_number': 592},\n",
       " 'Harakiri (1962)': {'rating': '8.6',\n",
       "  'director': 'Masaki Kobayashi',\n",
       "  'duration': '2 h 13 min. ',\n",
       "  'genres': 'Drame',\n",
       "  'ranking': '2. Harakiri (1962)',\n",
       "  'film_year': '1962',\n",
       "  'original_title': None,\n",
       "  'stars': '8.2K',\n",
       "  'saves': '12.7K',\n",
       "  'favorites': '1.5K',\n",
       "  'critique_number': 115},\n",
       " 'Blade Runner : The Final Cut (2007)': {'rating': '8.6',\n",
       "  'director': 'Ridley Scott',\n",
       "  'duration': '1 h 57 min. ',\n",
       "  'genres': 'Science-fiction',\n",
       "  'ranking': '3. Blade Runner : The Final Cut (2007)',\n",
       "  'film_year': '2007',\n",
       "  'original_title': None,\n",
       "  'stars': '1.2K',\n",
       "  'saves': '268',\n",
       "  'favorites': '111',\n",
       "  'critique_number': 3}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_request = RequestSensCritique()\n",
    "\n",
    "top_111_link = 'films/tops/top111'\n",
    "create_request.get_main_page(top_111_link, search_dict_main_page,search_dict_film_page )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
